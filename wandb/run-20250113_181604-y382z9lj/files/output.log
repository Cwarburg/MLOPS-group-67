Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:07<00:00, 3380.98 examples/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/Users/christianwarburg/Desktop/MLOps-Project-Group-67/.venv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  4%|█████▏                                                                                                                        | 383/9375 [08:14<3:52:38,  1.55s/it]Traceback (most recent call last):
{'loss': 0.6237, 'grad_norm': 11.609033584594727, 'learning_rate': 1.9786666666666668e-05, 'epoch': 0.03}
{'loss': 0.4292, 'grad_norm': 4.080662250518799, 'learning_rate': 1.9573333333333335e-05, 'epoch': 0.06}
{'loss': 0.3631, 'grad_norm': 7.403373718261719, 'learning_rate': 1.936e-05, 'epoch': 0.1}
  File "/Users/christianwarburg/Desktop/MLOps-Project-Group-67/src/mlopsgroup67/train.py", line 91, in <module>
    train_model()
  File "/Users/christianwarburg/Desktop/MLOps-Project-Group-67/src/mlopsgroup67/train.py", line 80, in train_model
    trainer.train()
  File "/Users/christianwarburg/Desktop/MLOps-Project-Group-67/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
  File "/Users/christianwarburg/Desktop/MLOps-Project-Group-67/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2536, in _inner_training_loop
    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))
KeyboardInterrupt
